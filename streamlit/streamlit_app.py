import streamlit as st
from streamlit_shap import st_shap

import pandas as pd
import numpy as np
import io
import base64
import pickle
import sklearn
from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns
import matplotlib.pyplot as plt
import shap
shap.initjs() # for visualization

########################################################################################################################################################################
# D√©finition du main()
########################################################################################################################################################################

def main():
	st.sidebar.title("RainsBerry")
	#st.set_page_config(
	#page_title="RainsBerry - M√©t√©o",
	#page_icon="üëã",
	#layout="wide",)
	Menu = st.sidebar.radio(
		"Menu",
		('Le Projet M√©t√©o', 'Dataset & PreProcessing','DataViz','Modelisations','Performances','Simulations','Clustering','S√©ries Temporelles','Conclusion'))
	if Menu == 'Le Projet M√©t√©o':
		from PIL import Image
		image = Image.open('images/RainsBerry_2.jpg')
		st.image(image,width=600,caption="")
		'''
		* Le projet pr√©sent√© dans ce streamlit a √©t√© d√©velopp√© dans le cadre de la formation Data Scientist de Datascientest.com - Promotion Octobre 2021.
		* L'objectif premier de ce projet est de mettre en application les diff√©rents acquis de la formation sur la probl√©matique de pr√©vision m√©t√©o et plus pr√©cis√©ment de r√©pondre √† une question essentielle: va-t-il pleuvoir demain?
		'''
		st.image('images/Intro_m√©t√©o.jpg',width=650,caption="")
		'''
		* En dehors d'int√©resser particuli√®rement les fabricants de parapluie, on comprend aussi que cette question est essentielle que ce soit dans le domaine des loisirs (gestion des parcs d'attraction), de l'agriculture, du traffic routier, et bien d'autres sujets.
		* Le lien du repo github est disponible ici: https://github.com/DataScientest-Studio/RainsBerryPy.
		'''
	if Menu == 'Dataset & PreProcessing':
		PreProcessing()
	if Menu == 'DataViz':
		DataViz()
	if Menu == 'Modelisations':
		Modelisations()
	if Menu == 'Performances':
		Performances()
	if Menu == 'Simulations':
		simulation()
	if Menu == 'Clustering':
		clustering()
	if Menu == 'Conclusion':
		conclusion()
	if Menu == 'S√©ries Temporelles':
		serie_temp()
	if Menu == 'Rapport':
		rapport()
	st.sidebar.text("")
	st.sidebar.text("Projet DataScientest")
	st.sidebar.text("Promotion DataScientist Octobre 2021")
	st.sidebar.text("Lionel Bottan")
	st.sidebar.text("Julien Coquard")
	st.sidebar.text("Samuel Gu√©rin")
	st.sidebar.write("[Lien du git](https://github.com/DataScientest-Studio/RainsBerryPy)")

########################################################################################################################################################################
# D√©finition de la partie Preprocessing
########################################################################################################################################################################
    
def PreProcessing():
	from PIL import Image
	st.header("Dataset & PreProcessing")
	image = Image.open('images/weatherAUS.jpg')
	st.image(image, caption='Relev√© M√©t√©o en Australie',width=600)
	st.subheader("Dataset originel")
	df=pd.read_csv('data/weatherAUS.csv') #Read our data dataset
	buffer = io.StringIO()
	df.info(buf=buffer)
	s = buffer.getvalue()
	st.write("Pr√©sentation du jeu de donn√©es : ")
	'''
	Le jeu de donn√©es poss√®de 145 460 entr√©es et 23 colonnes dont :
	* La date de l'observation (Date).
	* La ville dans laquelle se situe la station m√©t√©o (Location). 
	* La variable cible RainTomorrow dont la valeur (Yes ou No) indique s'il a plu ou non le lendemain de l'observation.
	* 20 variables d√©crivant les conditions atmosph√©riques du jour de l‚Äôobservation :
	'''
	st.text(s)
	'''
	Remarques :
	* Les valeurs de la variable RainToday (Yes, No) sont d√©finies par la variable Rainfall (Yes si pr√©cipitations > 1mm).
	* Plusieurs variables poss√®dent de nombreuses valeurs manquantes que l'on a g√©r√© de la mani√®re suivante:
	* Soit par exclusion pur et simple des entr√©es avec valeurs manquantes
	* Soit par l'utilisation d'un transformeur KNN: https://medium.com/@kyawsawhtoon/a-guide-to-knn-imputation-95e2dc496e
	'''
	st.subheader("Ajout de nouvelles donn√©es")
	st.write("Principaux climats australiens",width=600)
	image = Image.open('images/grd_climats.png')
	st.image(image, caption='Climats australiens',width=600)
	st.write("Classification de K√∂ppen")
	image = Image.open('images/clim_koppen.png')
	st.image(image, caption='Climats - Classification de Koppen',width=600)
	df=pd.read_csv('data/climatsAUS_v2.csv') #Read our data dataset
	buffer = io.StringIO()
	df.info(buf=buffer)
	s = buffer.getvalue()
	st.write("Pr√©sentation du jeu de donn√©es : ")
	st.text(s)
	st.write("Coordonn√©es GPS")
	image = Image.open('images/GPS.jfif')
	st.image(image, caption='Coordonn√©es GPS')
	df=pd.read_csv('data/aus_town_gps.csv') #Read our data dataset
	buffer = io.StringIO()
	df.info(buf=buffer)
	s = buffer.getvalue()
	st.write("Pr√©sentation du jeu de donn√©es : ")
	st.text(s)
	'''
	###Preprocessing
	Cr√©ation de nouvelles donn√©es:
	* Num√©risation des deux variables bool√©ennes RainToday et RainTomorrow.
	* D√©composition de la date en trois variables : Ann√©e, Mois, Jour.
	* Climat_Koppen : classe climatique dans la classification de K√∂ppen.
	* Clim_type : type de climat regroupant plusieurs classes de K√∂ppen, d√©finie √† partir de Climat_Koppen
	* Ajout de 3x3 variables pr√©cisant la direction des vents (d√©finies √† partir de WindGustDir, WindDir9am et WindDir3pm) :
		* WindGust_Ang, Wind9am_Ang, Wind3pm_Ang : angle correspondant (en degr√©s) sur le cercle trigonom√©trique (ie. E=0¬∞ et rotation dans le sens direct).
		* WindGust_cos, Wind9am_cos, Wind3pm_cos : cosinus de l'angle (abscisse des coordonn√©es trigo).
		* WindGust_sin, Wind9am_sin, Wind3pm_sin : sinus de l'angle (ordonn√©e des coordonn√©es trigo). 
	* Pluie √† J-1, J-2, J+1, J+2
	* Circularisation de la variable Mois (https://datascientest.com/numeriser-des-variables). De cette fa√ßon, les mois de d√©cembre et janvier ont des valeurs proches.
	###
	### Gestion des valeurs manquantes:
	* DropNa pour Mani√®re brute: 56k entr√©es
	* Interpolate et KNN imputer: 145k entr√©es
	'''
	


########################################################################################################################################################################
# D√©finition de la partie DataViz
########################################################################################################################################################################
 
def DataViz():
    st.header("DataViz")
    if st.checkbox("Corr√©lations de la pluie du lendemain (RainTomorrow) et de  l'ensoleillement (Sunshine)"):
        st.image('images/Dataviz_corr.jpg')
        '''
        #### Observations :
        * L‚Äôanalyse des corr√©lations nous montre que les liaisons entre les diff√©rents crit√®res sont nombreuses.
        * Quelles sont les variables les plus corr√©l√©es √† RainTomorrow ?
            * Ensoleillement : Sunshine
            * Humidit√© : 3pm et 9am
            * Couverture nuageuse : 3pm et 9am
            * Pluie du jour : RainToday
            * Pression atmosph√©rique : Pressure3pm et Pressure9am
        * L'ensoleillement (Sunshine) est corr√©l√© √† RainTomorow_num malgr√© presque 50% de valeurs manquantes pour cette variable. Quand on regarde les corr√©lations, on peut imaginer de traiter ces valeurs manquantes en r√©gressant Sunshine sur les crit√®res les plus corr√©l√©s, √† savoir :
            * Couverture nuageuse : 3pm et 9am
            * Humidit√© : 3pm et 9am
            * Temp√©rature : Temp3pm, MaxTemp, Temp9am
        '''       
    if st.checkbox("Cartographie"):
        st.image('images/Dataviz_carto.jpg')
        '''
        #### Observations : 
        * Les stations m√©t√©o d'Australie sont regroup√©es en 4 climats diff√©rents :
            * m√©diterrann√©en : stations du sud-ouest et du sud-centre
            * chaud_humide (tropical et subtropical humide) => c√¥te est du pays
            * temp√©r√©_froid (temp√©r√© oc√©anique + montagnard) => plut√¥t sud-est
            * sec (chaud et semi-aride, voire aride) => int√©rieur du pays
        * La distribution mensuelle des pr√©cipitations illustre bien les diff√©rences de climat (mousson estivale pour le climat tropical, hivernale pour le climat m√©diterran√©en).
        * Pour les stations au climat sec, on observe 9% de jours de pluie alors que pour les autres on est aux alentours de 22, 23%.
        '''       
    if st.checkbox("Influence sur la pluie du lendemain"):
        st.image('images/Dataviz_influence.jpg')
        '''
        #### Constats :
        * La distribution des variables Sunshine et Humidity3pm est bien diff√©rente selon RainTomorrow.
        * Pour MinTemp, la distribution est relativement similaire.
        * Pour Rainfall et Evaporation, il faut appliquer la fonction log pour neutraliser l'influence des valeurs extr√™mes. On voit aussi l'influence plus importante de Rainfall sur RainTomorrow (distribution diff√©rente).
        '''      
	
########################################################################################################################################################################
# D√©finition de la partie mod√©lisation
########################################################################################################################################################################

def Modelisations():
    st.header("Mod√©lisations")
    
    Menu_mod = st.sidebar.radio(
     "Menu Mod√©lisations",
     ('Equilibrage des classes','Traitement des valeurs manquantes','S√©lection de variables', 'Conclusion'))

    def Equilibrage():
        st.subheader("√âquilibrage des classes")
        st.image('images/model_01_desequilibre.jpg')
        st.markdown("**Performances d'un mod√®le Random Forest sur le jeu de donn√©es complet :**")
        st.image('images/model_02_sans_equ.jpg')
        if st.checkbox("Apr√®s √©quilibrage"):
            st.image('images/model_03_avec_equ.jpg')
            st.image('images/model_04_PrecRap.jpg')
        if st.checkbox("Modification du seuil de d√©tection de la classe 1"):
            st.image('images/model_05_seuils_proba.jpg')
            st.image('images/model_06_seuilmaxF1.jpg')
	            
    def TraitementNA():
        st.subheader("Traitement des valeurs manquantes")
        '''
        #### **Hypoth√®se : Les performances d√©pendent de la m√©thode de traitement des valeurs manquantes.**
        ##### Trois techniques ont √©t√© utilis√©es pour traiter les valeurs manquantes et cr√©er trois jeux de donn√©es : 
        * Remplacement des valeurs manquantes par la m√©thode KNN-Imputer.
        * Suppression des observations poss√©dant des valeurs manquantes par la m√©thode dropna.
        * Suppression des quatre variables poss√©dant le plus de valeurs manquantes, puis suppression des observations restantes poss√©dant des NaN.
        '''       
        st.image('images/model_07_proportionsNA.jpg')
        if st.checkbox("Scores"):
            st.markdown("**Scores en fonction du jeu de donn√©es :**")
            st.image('images/model_08_scores_JD.jpg')
            '''
            ##### Conclusion : Le jeu de donn√©es dropna pr√©sentent les meilleures performances, en plus d'√™tre le plus rapide.
            '''
	
    def SelectionVar():
        st.subheader("S√©lection de variables")
        '''
        #### **Hypoth√®se : Des variables peu pertinentes perturbent le mod√®le, ce qui affecte ses performances.**
        '''
        st.image('images/model_09_selectKBest.jpg') 
        '''
        ##### Conclusion : √Ä partir de six variables, on observe une croissance de toutes les m√©triques au fur et √† mesure qu‚Äôon int√®gre des variables au mod√®le. 
        ##### Il n'est donc pas n√©cessaire de supprimer des variables pour am√©liorer les scores.
        '''
  
    def Conclusion():
        st.subheader("Conclusion")
        '''
        * Le r√©√©chantillonnage permet d'obtenir des scores l√©g√®rement meilleurs, mais c'est surtout le choix du seuil de d√©cision qui a le plus d'impact sur les performances.
        * L'interpolation des valeurs manquantes par KNN Imputer r√©duit les performances au lieu de les am√©liorer. Il est pr√©f√©rable d‚Äôutiliser un jeu de donn√©es o√π les valeurs manquantes ont simplement √©t√© supprim√©es.
        * Le retrait de certaines variables n‚Äôam√©liore pas les performances. Toutes les variables peuvent √™tre utilis√©es pour entrainer nos mod√®les.
        '''
         
    if Menu_mod == 'Equilibrage des classes':
        Equilibrage()
        
    if Menu_mod == 'Traitement des valeurs manquantes':
        TraitementNA()
        
    if Menu_mod == 'S√©lection de variables':
        SelectionVar()
        
    if Menu_mod == 'Conclusion':
        Conclusion()

########################################################################################################################################################################
# D√©finition de la partie perfomance
########################################################################################################################################################################

def Performances():
    st.header("Performances des mod√®les test√©s")
    '''
    #### Les algorithmes suivants ont √©t√© test√©s en prenant en compte les r√©sultats des analyses pr√©c√©dentes :
    * R√©√©quilibrage du jeu de donn√©es avec RandomUnderSampler. 
    * Conservation de toutes les variables pr√©dictives.
    * Choix de l'algorithme sur le dataset sans les NA (donn√©es r√©elles)
    * En revanche, application possible sur les donn√©es interpol√©es ce qui aurait l'int√©r√™t de pouvoir avoir des pr√©dictions sur les observations qui ont des valeurs manquantes (par exemple, les stations  qui ne mesurent pas certains indicateurs). 

    #### Liste des algorithmes test√©s :
    * Arbre de d√©cision
    * Boosting sur arbre de d√©cision (Adaboost classifier)
    * Isolation Forest (d√©tection d‚Äôanomalies) => non pr√©sent√© car vraiment trop d√©grad√©.
    * R√©gression logistique
    * SVM
    * KNN
    * Random Forest
    * Light GBM
    * Bagging Classifier
    * Stacking Classifier (avec les mod√®les pr√©entrain√©s RandomForest, SVM et LogisticRegression)
	
    ##### Optimisation des mod√®les :
    * Une grille de recherche sur les hyperparam√®tres a √©t√© construite pour les mod√®les avec le choix de maximiser le f1 comme m√©trique de performance et 3 folds pour limiter le surapprentissage.

    ##### Choix du mod√®le :
    * Le mod√®le final sera choisi au regard de la courbe de ROC, de l'AUC globale et surtout des m√©triques f1_score, precision, rappel sur la classe √† mod√©liser.

    ##### D√©finitions :
    * La precision correspond au taux de pr√©dictions correctes parmi les pr√©dictions positives. Elle mesure la capacit√© du mod√®le √† ne pas faire d‚Äôerreur lors d‚Äôune pr√©diction positive.
    * Le recall correspond au taux d‚Äôindividus positifs d√©tect√©s par le mod√®le. Il mesure la capacit√© du mod√®le √† d√©tecter l‚Äôensemble des individus positifs.
    * Le F1-score √©value la capacit√© d‚Äôun mod√®le de classification √† pr√©dire efficacement les individus positifs, en faisant un compromis entre la precision et le recall (moyenne harmonique).
    ''' 
    if st.checkbox("Courbe de ROC"):
        st.image('images/Perf_ROC.jpg')       
    if st.checkbox("Selon le seuil de d√©tection"):
        st.image('images/Perf_seuils.jpg')
        st.image('images/Perf_seuils1.jpg')
    if st.checkbox("Deep Learning"):
        '''
        L‚Äôobjectif de cette section est de tester des mod√®les de Deep Learning pour pr√©dire RainTomorrow et de comparer les performances obtenues aux mod√®les de Machine Learning classique pr√©sent√©s ci dessus.
        * 2 types de r√©seaux de neurones ont √©t√© test√©s :
        '''
        if st.checkbox("1-Mod√®les denses classiques"):
            '''
            * Plusieurs mod√®les ont √©t√© construits en faisant varier les caract√©ristiques suivantes :
                * Augmentation du nombres de couches : de 4 √† 5 couches de neurones
                * Augmentation du nombre de neurones des couches
                * Changement de la fonction d‚Äôactivation : tanh, ReLu
                * Changement de l‚Äôinitialisateur : normal, Xavier, HeNormal
                * Diminution de la taille du batch : 32, 16
            * L‚Äôensemble des r√©sultats obtenus par les premiers mod√®les sont assez similaires, les performances ne sont pas significativement diff√©rentes, en particulier si l‚Äôon consid√®re les variations d‚Äôun entrainement √† l‚Äôautre. 
            * Le meilleur mod√®le donne les r√©sultats suivants (apr√®s r√©√©chantillonnage) :
            '''
            st.image('images/DeepLearning_dense.jpg')
        if st.checkbox("2-Fast AI"):
            '''
            * Pour compl√©ter l‚Äô√©tude ci-dessus, un mod√®le de Deep Learning utilisant la biblioth√®que FastAI a √©t√© d√©velopp√© en s‚Äôinspirant de la litt√©rature disponible sur le web :
            * Les performances obtenues par le mod√®le sont report√©es dans les tableaux ci-dessous :
            '''
            st.image('images/DeepLearning_FastAI.jpg')
        if st.checkbox("3-Conclusion Deep Lerning"):
            '''
            * Les mod√®les de Deep Learning d√©velopp√©s n‚Äôont pas d√©montr√© de meilleurs r√©sultats que les mod√®les de Machine Learning classique √©tudi√©s en d√©but de projet.
            * Par ailleurs, au-del√† des performances peu convaincantes sur notre jeu de donn√©es, le manque d‚Äôinterpr√©tabilit√© des mod√®les de Deep Learning par rapport au Machine Learning classique ne pousse pas √† les d√©velopper davantage lors de ce projet.
            '''        
    if st.checkbox("Conclusion"):
        '''
        * La comparaison des algorithmes sur la courbe de ROC nous donne une liste de quatre algorithmes sensiblement plus performants que les autres :
            * la Random Forest
            * le Bagging
            * la XGBoost
            * la Light GBM
        
        * Les comparaisons sur le F1_score en choisissant diff√©rents seuils de probabilit√©s (0.50, F1_max, recall=precision) vont nous conduite √† pr√©f√©rer la XGBOOST qui est l√©g√®rement plus performante que la lightGBM sur le seuil "recall=precision".
        * Les mod√®les de Deep Learning d√©velopp√©s n‚Äôont pas d√©montr√© de meilleurs r√©sultats que les mod√®les de Machine Learning classique √©tudi√©s en d√©but de projet.
        '''
        st.image('images/Perf_conclusion1.jpg')
        if st.checkbox("Interpr√©tabilit√© de notre mod√®le final XGBOOST"):
            '''
            * L'interpr√©tabilit√© est importante d√®s que les r√©sultats d'un mod√®le influent grandement sur des d√©cisions importantes. En entreprise par exemple, expliquer √† des √©quipes non-initi√©es le fonctionnement d'un mod√®le pose toujours son lot de d√©fis.
            * Ici nous ne pr√©sentons que l'interpr√©tabilit√©  avec Shapash (Shapash est une librairie Python qui vise √† rendre le Machine Learning intelligible par le plus grand nombre. Concr√®tement, il s‚Äôagit d‚Äôune surcouche √† d‚Äôautres librairies d‚Äôintelligibilit√© (Shap, Lime))
            * Interpr√©tabilit√© globale
            '''
            st.image('images/Interpretabilite_globale.jpg')
            '''
            * Interpr√©tabilit√© locale
            '''            
            st.image('images/Interpretabilite_locale.jpg')

        
########################################################################################################################################################################
# D√©finition de la partie simulation
########################################################################################################################################################################

def simulation():
    #Chargement du modele
    picklefile = open("modeles/xgboost.pkl", "rb")
    modele = pickle.load(picklefile)  

    #Definition des features
    features = ["RainToday_Num","Rain_J-1","Rain_J-2","MinTemp","MaxTemp","Sunshine","Evaporation",
        "Humidity3pm","Humidity9am","Pressure9am","Pressure3pm","Cloud3pm","Cloud9am", 
        "Wind9am_cos","Wind3pm_cos","WindGust_cos","Wind9am_sin","Wind3pm_sin","WindGust_sin", 
        "Mois","Clim_type_det"]
                
    st.markdown("# Simulation")

    st.subheader("Lecture des donn√©es")

    Data = st.selectbox("DataFrame: " , ["echantillon","Sydney","AliceSprings","Darwin","Perth","Hobart"])

    if ( Data == "echantillon"):
        df=pd.read_csv('data/echantillon.csv') #Read our data dataset
    if ( Data == "Sydney"):
        df=pd.read_csv('data/Sydney.csv') #Read our data dataset
    if ( Data == "AliceSprings"):
        df=pd.read_csv('data/AliceSprings.csv') #Read our data dataset
    if ( Data == "Darwin"):
        df=pd.read_csv('data/Darwin.csv') #Read our data dataset
    if ( Data == "Perth"):
        df=pd.read_csv('data/Perth.csv') #Read our data dataset
    if ( Data == "Hobart"):
        df=pd.read_csv('data/Hobart.csv') #Read our data dataset    

    st.write("Nombre de lignes : ", df.shape[0]) 
    st.write("Nombre de colonnes : ", df.shape[1]) 

    st.subheader("DataViz")

    DataViz = st.selectbox("Quelle Dataviz ? : " , ["Part jours de Pluie","Correlation","Analyse mensuelle","Impact de RainTomorrow"])

    if ( DataViz == "Part jours de Pluie"):
        #Part des jours de pluie
        fig = plt.figure(figsize=(3,3))
        x = df.RainTomorrow_Num.value_counts(normalize=True)
        colors = sns.color_palette('pastel')[0:5]
        labels = ['Pas de pluie', 'Pluie']
        plt.pie(x, labels = labels, colors = colors, autopct='%.0f%%')
        plt.title("Part des jours de pluie")
        st.write(fig)

    if ( DataViz == "Correlation"):
        fig, ax = plt.subplots(figsize=(15,6))
        ListeCrit = ["RainTomorrow_Num","MinTemp","MaxTemp","Sunshine","Evaporation","Humidity3pm"]
        sns.heatmap(df[ListeCrit].corr(), cmap="YlGnBu",annot=True,ax=ax)
        st.write(fig)

        fig = plt.figure( figsize= (20, 7) )
        ax1 = fig.add_subplot(121)
        ax2 = fig.add_subplot(122)
        corr = df.corr()
        ax1.title.set_text('Correlations de RainTomorrow')
        temp = corr[["RainTomorrow_Num"]].loc[abs(corr["RainTomorrow_Num"]) > 0.2].sort_values(by="RainTomorrow_Num",ascending=False)
        sns.heatmap(temp, cmap="YlGnBu",annot=True,ax=ax1)
        ax2.title.set_text('Correlations de Sunshine')
        temp = corr[["Sunshine"]].loc[abs(corr["Sunshine"]) > 0.2].sort_values(by="Sunshine",ascending=False)
        sns.heatmap(temp , cmap="YlGnBu",annot=True,ax=ax2)
        st.write(fig)


    if ( DataViz == "Analyse mensuelle"):
        fig, ax = plt.subplots(figsize=(15,6))
        ax.title.set_text("Distribution mensuelle des pluies")
        sns.lineplot(ax=ax,data=df, x="Mois", y="Rainfall")
        st.write(fig)

    if ( DataViz == "Impact de RainTomorrow"):
        fig, ax = plt.subplots(figsize=(20,4))
        plt.subplot(131)
        sns.histplot(data=df, x="Sunshine",hue="RainTomorrow_Num",bins=20, multiple="layer", thresh=None)
        plt.subplot(132)
        sns.histplot(data=df, x="MinTemp",hue="RainTomorrow_Num",bins=20, thresh=None)
        plt.subplot(133)
        sns.histplot(data=df, x="Humidity3pm",hue="RainTomorrow_Num",bins=20)
        st.write(fig)

    st.subheader("Pr√©diction")

    if st.button("Predict"):  
        #Courbe de ROC
        probs = modele.predict_proba(df[features])
        y_test =  df["RainTomorrow_Num"]
        fpr, tpr, seuils = sklearn.metrics.roc_curve(y_test, probs[:,1], pos_label=1)
        roc_auc = sklearn.metrics.auc(fpr, tpr)
        fig = plt.figure(figsize=(15,6))
        plt.plot(fpr, tpr, color='purple',  linestyle='--', lw=1, label='Model (auc = %0.3f)' % roc_auc)
        plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle=':', label='Al√©atoire (auc = 0.5)')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('Taux faux positifs')
        plt.ylabel('Taux vrais positifs')
        plt.title('Courbe ROC')
        plt.legend(loc="lower right");
        st.pyplot(fig)
    
        #Graphe selon le seuil 
        precision, recall, thresholds = precision_recall_curve(y_test, probs[:, 1], pos_label=1)
        dfpr = pd.DataFrame(dict(precision=precision, recall=recall, threshold=[0] + list(thresholds)))
        dfpr['F1']= 2 * (dfpr.precision * dfpr.recall) / (dfpr.precision + dfpr.recall)
        dfrpr_maxF1 = dfpr[dfpr.F1 == dfpr.F1.max()].reset_index()
        Seuil = dfrpr_maxF1["threshold"].values[0]
        dfpr["Diff_Recall_Precision"] = np.abs(dfpr["recall"]-dfpr["precision"])
        dfrpr_MinDiff = dfpr[dfpr.Diff_Recall_Precision == dfpr.Diff_Recall_Precision.min()].reset_index()
        Seuil1 = dfrpr_MinDiff["threshold"].values[0]
    
        fig = plt.figure(figsize=(15,6))
        plt.plot(dfpr["threshold"], dfpr['precision'],label="precision")
        plt.plot(dfpr["threshold"], dfpr['recall'],label="recall")
        plt.plot(dfpr["threshold"], dfpr['F1'],label="F1")
        plt.axvline(x=0.50,color="gray",label="seuil √† 0.50")
        plt.axvline(x=Seuil,color="red",label="seuil maximisant F1")
        plt.axvline(x=Seuil1,color="purple",label="seuil Recall=Precision")
        plt.title("Choix du seuil sur la classe √† mod√©liser")
        plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')
        st.pyplot(fig)
        #Matrice de confusion
        y_pred = np.where(probs[:,1] >= 0.50, 1, 0)    
        y_pred_best = np.where( probs[:,1] >= Seuil, 1, 0)
        y_pred_best1 = np.where( probs[:,1] >= Seuil1, 1, 0)
        st.text('Matrice de confusion seuil 0.50 :\n ' + classification_report(y_test, y_pred))
        st.text('Matrice de confusion seuil maximisant F1 :\n ' + classification_report(y_test, y_pred_best))
        st.text('Matrice de confusion seuil Recall=Precision :\n ' + classification_report(y_test, y_pred_best1))    
        fig = plt.figure(figsize=(15,6))
        cm = confusion_matrix(y_test, y_pred_best)
        ConfusionMatrixDisplay(cm).plot()
        st.pyplot(fig)
        #Predictions
        prediction = modele.predict(df[features])
        predDf = pd.DataFrame(prediction,columns=["prediction"])
        Sortie = pd.concat([df[["Date","Location","Climat_Koppen","Clim_type_det","RainTomorrow_Num"]],predDf],axis=1)
        #st.write(Sortie)

    #st.subheader("Interpr√©tabilit√©")
    
    #if st.button("Importance des features"):
    #    picklefile = open("modeles/xgboost.pkl", "rb")
    #    modele = pickle.load(picklefile)  
    #    explainer = shap.TreeExplainer(modele)
    #    shap_values = explainer.shap_values(df[features])
    #    st_shap(shap.summary_plot(shap_values, df[features]),height=300)

########################################################################################################################################################################
# D√©finition de la partie s√©ries temporelles
########################################################################################################################################################################
    
def serie_temp():
	Menu_mod = st.sidebar.radio("S√©ries temporelles",('Introduction & m√©thodologie','1√®re √©tude','2nde √©tude'))	
		
	def Intro():
		st.subheader('')
		'''
		## Introduction & M√©thodologie
		Cette section traite des s√©ries temporelles sur diff√©rents indicateurs. Notre choix s‚Äôest port√© sur les indicateurs suivants :
		* RainFall, le niveau de pr√©cipitation en mm
		* Humidity3pm, le taux d'humidit√© √† 15h
		* MaxTemp, la temp√©rature maximale.
		Deux √©tudes distinctes ont √©t√© men√©es :
		* √âtude sur sept villes repr√©sentatives des climats australiens:
		'''
		st.image('images/ST_Liste_Villes.jpg',width=600)
		st.image('images/ST_Carte_Villes.jpg',width=600)
		'''
		* √âtude sur deux climats aux saisons des pluies oppos√©es, en regroupant l‚Äôensemble des stations. Cette √©tude se limitera √† Rainfall:
		'''
		st.image('images/ST_Carte_Villes_2.jpg',width=600)
		'''
		## M√©thodologie:
		* Interpolation des valeurs manquantes sur les donn√©es quotidiennes.
		* Pr√©visions faites sur les donn√©es mensuelles.
		* Conservation des 24 derniers mois comme base de validation des mod√®les.
		* Algorithmes test√©s :
			* Autoarima : pour trouver les meilleurs param√®tres des SARIMA
			* SARIMAX : pour appliquer notre mod√®le final (qui peut √™tre ajust√© par rapport √† l‚ÄôAutoarima)
			* Prophet (algorithme de Facebook) en compl√©ment de SARIMAX.
		* Comparaison des performances des mod√®les : 
			* Deux m√©triques de mesure de l‚Äôerreur :
				* RMSE (erreur moyenne quadratique) : MaxTemp et Humidity3pm
				* WMAPE (Weighted Mean Absolute Percentage Error) pour RainFall
				=> M√©trique int√©ressante pour √©valuer les erreurs lorsque les valeurs r√©elles sont nulles ou proches de z√©ro. (https://resdntalien.github.io/blog/wmape/)
				* Pourcentage de corr√©lation de Pearson entre les valeurs r√©elles et pr√©dites.
		Remarque : D‚Äôautres m√©triques, telle que la MAE, ont √©t√© calcul√©es. Elles pr√©sentent toutes des r√©sultats concordants pour l‚Äôensemble des mod√®les test√©s et ne seront pas pr√©sent√©es.
		'''
		
	def Results_1():
		st.subheader('')
		'''
		# √âtude sur les villes repr√©sentatives des climats australiens -
		## Visualisation de l‚Äô√©volution des moyennes mensuelles pour les trois indicateurs:
		'''
		st.image('images/ST_CourbeIndic_Rainfall.jpg',width=600)
		st.image('images/ST_CourbeIndic_Hum3pm.jpg',width=600)
		st.image('images/ST_CourbeIndic_MaxTemp.jpg',width=600)
		'''
		## Observations et interpr√©tations:
		* La saisonnalit√© de Rainfall est particuli√®rement marqu√©e pour Cairns et Darwin avec un pic de pr√©cipitations important en f√©vrier. Ces deux villes √©tant situ√©es en climat tropical, elles poss√®dent une p√©riode de mousson importante en √©t√©.
		* Pour Humidity3pm, la saisonnalit√© n‚Äôest pas tr√®s marqu√©e mais les niveaux sont bien diff√©rents entre AliceSprings (climat sec) et Norfolk Island (climat humide).
		* MaxTemp poss√®de une saisonnalit√© importante pour les villes situ√©es au sud (climats m√©diterran√©en et oc√©anique), tandis que les villes situ√©es plus proche de l‚Äô√©quateur (Cairns et Darwin ‚Äì climat tropical) pr√©sentent un hiver beaucoup plus doux et donc une saisonnalit√© moins marqu√©e.
		Les deux sous-sections suivantes d√©taillent les r√©sultats obtenus pour deux villes : Canberra et Cairns.
		## R√©sultats obtenus pour :
		'''
		if st.checkbox('Canberra'):
			st.image('images/ST_ResultTab_Camberra.jpg',width=600)
			st.image('images/ST_ResultCurv_Camberra_Rainfall.jpg',width=600)
			st.image('images/ST_ResultCurv_Camberra_Hum3pm.jpg',width=600)
			st.image('images/ST_ResultCurv_Camberra_MaxTemp.jpg',width=600)
		if st.checkbox('Cairns'):
			st.image('images/ST_ResultTab_Cairns.jpg',width=600)
			st.image('images/ST_ResultCurv_Cairns_Rainfall.jpg',width=600)
			st.image('images/ST_ResultCurv_Cairns_Hum3pm.jpg',width=600)
			st.image('images/ST_ResultCurv_Cainrs_MaxTemp.jpg',width=600)
		'''
		## Conclusion:
		Comme on pouvait s‚Äôy attendre, les variations al√©atoires quotidiennes rendent les pr√©dictions plus difficiles sur Rainfall que sur MaxTemp, comme le montre la superposition des courbes des pr√©dictions et de la s√©rie originelle. Pour MaxTemp, le coefficient de corr√©lation d√©passe en effet 90 % pour tous les mod√®les. Humidity3pm pr√©sente sur ce point, un profil interm√©diaire. Pour les trois indicateurs m√©t√©orologiques, les performances sont meilleures sur Cairns que sur Canberra. La diff√©rence entre les deux villes est particuli√®rement marqu√©e pour Rainfall, avec un coefficient de corr√©lation de 61 % pour Cairns (comparable √† celui d‚ÄôHumidity), alors qu‚Äôil n‚Äôest que de 20 % pour Canberra. Cette diff√©rence peut s‚Äôexpliquer si l‚Äôon prend en compte le climat des deux villes. Cairns pr√©sente en effet un climat tropical, avec des saisons plus marqu√©es en termes de pr√©cipitations que Canberra, dont le climat est oc√©anique.
		'''
		
	def Results_2():
		st.subheader('')
		'''
		# √âtude sur deux climats aux saisons des pluies oppos√©es -
		## Ici on s‚Äôint√©resse non plus √† une ville mais √† la moyenne mensuelle de l‚Äôensemble des villes d‚Äôun climat donn√©.
		## Hypoth√®se de travail : 
		* La variable Rainfall pr√©sente une forte p√©riodicit√© pour les climats caract√©ris√©s par une p√©riode de mousson : 
		* climat tropical (Aw + Am)
		* et climat m√©diterran√©en (Csa + Csb).
		La p√©riode de mousson est diff√©rente en climat m√©diterran√©en (mousson hivernale) et en climat tropical (mousson estivale). Il est donc n√©cessaire d'√©tudier ces deux climats s√©par√©ment.
		La m√©thodologie est la m√™me que celle utilis√©e pour les analyse par ville.
		## Observations:
		'''
		st.image('images/ST_CourbeIndic_Rainfall_climat.jpg',width=600)
		st.image('images/ST_CourbeIndic_Rainfall_climat_saison.jpg',width=600)
		'''
		Les graphiques confirment notre hypoth√®se : les deux s√©ries poss√®dent une forte saisonnalit√© mais avec un d√©calage d'une demi-p√©riode environ.
		La moyenne mobile, calcul√©e sur 12 mois, √©volue peu, mais les s√©ries ne sont pas compl√®tement stationnaires. 
		Le climat tropical pr√©sente notamment une diminution des pics de pr√©cipitations apr√®s 2012.
		'''
		st.image('images/ST_ResultTab_RainfallClimat.jpg',width=600)
		st.image('images/ST_ResultCurv_Rainfall_med.jpg',width=600)
		st.image('images/ST_ResultCurv_Rainfall_trop.jpg',width=600)
		'''
		## Conclusion
		Les performances sont meilleures sur ces deux climats que sur les villes prises ind√©pendamment, avec des erreurs plus faible et un coefficient de corr√©lation d√©passant les 75 %. 
		On remarque aussi de performances l√©g√®rement meilleures pour le climat m√©diterran√©en que pour le climat tropical, si l‚Äôon consid√®re l‚Äôerreur WMAPE. Cette diff√©rence peut s‚Äôinterpr√©ter par une meilleure stationnarit√© de la s√©rie m√©diterran√©enne, visible en observant la courbe de la moyenne mobile
		'''
		
	if Menu_mod == 'Introduction & m√©thodologie':
		Intro()
	if Menu_mod == '1√®re √©tude':
		Results_1()
	if Menu_mod == '2nde √©tude':
		Results_2()

	

########################################################################################################################################################################
# D√©finition de la partie rapport
########################################################################################################################################################################
  
  
def rapport():
    st.write("[Lien git_hut :](https://github.com/DataScientest-Studio/RainsBerryPy)")
    def show_pdf(file_path):
        with open(file_path,"rb") as f:
            base64_pdf = base64.b64encode(f.read()).decode('utf-8')
        pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="800" height="800" type="application/pdf"></iframe>'
        st.markdown(pdf_display, unsafe_allow_html=True)

    show_pdf('https://github.com/SamuelGuerin-Git/RainsBerryPy_save/blob/cac5fac60f5e539aec938a343b8152b3587f9ba4/RainsberryPy%20Meteo%20-%20Rapport%20final.pdf')


########################################################################################################################################################################
# D√©finition de la partie conclusion g√©n√©rale
########################################################################################################################################################################
 
def conclusion():
    st.header("Conclusion")
    '''
    * Notre projet RainsBerryPy nous a permis de mettre en application les diff√©rents apprentissages de la formation de Datascientist commenc√©e en octobre 2021 : preprocessing, manipulation de dataframe, DataViz, Machine Learning, interpr√©tabilit√©, clustering, s√©ries temporelles et m√™me Deep Learning. 

    * Un projet complet qui nous a permis de mettre en avant notre esprit d‚Äôinitiative en recherchant :
        *   Des √©l√©ments n√©cessaires √† notre mod√©lisation : climat de K√∂ppen, circularisation de la variable mois, ‚Ä¶
        *   De nouvelles biblioth√®ques/algorithmes : KNN imputer, Light gbm, Shapash, tslearn, Prophet, FastAI‚Ä¶

    * Aussi, la collaboration au sein de notre groupe s‚Äôest tr√®s bien d√©roul√©e et a d√©montr√© que le travail en distanciel (devenue une norme depuis la crise sanitaire) n‚Äôentache en rien sa performance.
    * Nous tenions aussi √† remercier notre mentor Laur√®ne qui a su questionner notre travail et en assurer sa coh√©rence √† chaque it√©ration.

    ### Pour aller plus loin
    * les possibles √©volutions que nous pourrions apporter √† notre travail seraient les suivantes :
        * Ajout de variables de g√©olocalisation de la pluie : pour chaque ligne indiquer la distance de la ville la plus proche o√π il pleut,
        * Injection de notre r√©sultat de clustering dans notre mod√®le m√™me si les r√©sultats pourraient √™tre sensiblement similaires √† la classification de Koppen,
        * Ajout d‚Äôimages satellites au jeu de donn√©es avec utilisation d‚Äôalgorithmes de deep learning CNN voir RNN,
        * Utilisation d‚Äôalgorithme de deep learning RNN sur les s√©ries temporelles.
    '''

########################################################################################################################################################################
# D√©finition de la partie clustering
########################################################################################################################################################################
    
def clustering():
 
    Menu_mod = st.sidebar.radio(
     "Menu Clustering",
     ('Introduction et strat√©gie','1√®re √©tape: Type de climat','2√®me √©tape: R√©gime pluviom√©trique','3√®me √©tape: Variation de temp√©rature', 'Conclusion'))  
    
    def Intro():
        st.subheader("Introduction")
        st.image('images/clustering-in-machine-learning.jpg')

        ''' 
        #### La classification de K√∂ppen est une classification des climats fond√©e sur les pr√©cipitations et les temp√©ratures. Un climat, selon cette classification, est rep√©r√© par un code de deux ou trois lettres :
        * 1√®re lettre : type de climat 
        * 2√®me lettre : r√©gime pluviom√©trique 
        * 3√®me lettre : variations de temp√©ratures.
        #### La combinaison de ces sous-classifications donne la classification de climat de K√∂ppen suivante :
        '''        
        
        st.image('images/Climat de Koppen.jpg',caption='Classification de Koppen')
        ''' 
        ##### Strat√©gie Adopt√©e :
        * 1√®re lettre : type de climat => Algorithme KMeans
        * 2√®me lettre : r√©gime pluviom√©trique => TimeSeriesKmeans Clustering
        * 3√®me lettre : variations de temp√©ratures => TimeSeriesKmeans Clustering
        '''                
        
        
    def KMeans():
        st.subheader("Clustering: Type de climat => KMeans")
        '''
        ### Preprocessing:
        #### Cr√©ation d'un dataframe avec :
        * une ligne par ville
        * pour chaque variable consid√©r√©e, cr√©ation d'un jeu de douze colonnes avec le calcul de la moyenne mensuelle: 
            * 'MinTemp','MaxTemp','Temp9am','Temp3pm',
            * 'Rainfall',
            * 'Evaporation',
            * 'Sunshine',
            * 'WindGustSpeed','WindSpeed9am','WindSpeed3pm',
            * 'Humidity9am','Humidity3pm',
            * 'Pressure9am','Pressure3pm',
            * 'Cloud9am','Cloud3pm',
            * 'RainToday_Num'
        ### Utilisation de l'algorithme KMeans:
        #### M√©thode du coude pour d√©finir le nombre de clusters
        '''
        st.image('images/1L_Coude.jpg')
        '''
        #### Nous consid√©rons 10 clusters.
        
        ### Comparaison Classification de Koppen vs Clustering 
        '''
        st.image('images/1L_ResultatsTab.jpg')
        '''
        ### Comparaison localis√©e
        '''
        st.image('images/1L_ResultatsMap.jpg')
        '''
        #### => Climats extr√™mes bien identifi√©s mais r√©sultats moins convaincants pour les autres. 
        '''
    def TSClustering2L():
        st.subheader("Clustering: R√©gime pluviom√©trique => TimeSeriesKmeans")
        '''
        ### Preprocessing
        ##### S√©lection d'une plage de 3 ans et demi de donn√©es √† partir de janvier 2014 - Plus grand plages avec des relev√©s cons√©cutifs (donn√©es d'origine avec traitement KNN imputer).

        #### R√©sultats du Clustering de S√©ries Temporelles:
        '''
        st.image('images/2L_ResultatsPlot.jpg')
        '''
        ### Comparaison Classification de Koppen vs Clustering
        '''
        st.image('images/21L_ResultatsTab.jpg')
        '''
        ### Comparaison Localis√©e
        '''        
        st.image('images/2L_ResultatsMap.jpg')
        '''
        ##### => Le r√©gime de mousson est bien isol√© et le r√©gime f associ√© au climat humide se retrouve seul dans de nombreux clusters (hormis 1).
        '''
        
    def TSClustering3L():
        st.subheader("Clustering: Variation de temp√©rature")
        '''
        ### Preprocessing
        ##### Similaire √† la classification pr√©c√©dente

        #### R√©sultats du Clustering de S√©ries Temporelles:
        '''
        st.image('images/3L_ResultatsPlot.jpg')
        '''
        ### Comparaison Classification de Koppen vs Clustering
        '''
        st.image('images/3L_ResultatsTab.jpg')
        '''
        ### Comparaison Localis√©e
        '''
        st.image('images/3L_ResultatsMap.jpg')
        '''
        ##### => L‚Äôensemble des classifications des variations de temp√©rature est dans l‚Äôensemble bien ex√©cut√©.
        '''
    def Conclusion(): 
        st.subheader("Conclusion")
        '''
        ### Combinaison des diff√©rents clusters:
        '''
        st.image('images/Clust_ResultatsTab.jpg')
        '''
        #### 32 clusters diff√©rents identifi√©s
        '''
        st.image('images/FinalClust_ResultatsTab.jpg')
        '''
        #### Apr√®s regroupement des clusters identifi√©s sous la m√™me classification de Koppen:
        '''
        st.image('images/Final_ResultatsMap.jpg')
        
    if Menu_mod == 'Introduction et strat√©gie':
        Intro()
        
    if Menu_mod == '1√®re √©tape: Type de climat':
        KMeans()
        
    if Menu_mod == '2√®me √©tape: R√©gime pluviom√©trique':
        TSClustering2L()
        
    if Menu_mod == '3√®me √©tape: Variation de temp√©rature':
        TSClustering3L()
        
    if Menu_mod == 'Conclusion':
        Conclusion()
        
if __name__ == "__main__":
    main()
